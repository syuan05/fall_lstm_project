# æ¶ˆèå¯¦é©—çµ„åˆ¥ï¼šA2ï¼ˆBaseline, MAX_SEQ_LEN=144, yè»¸çµ±ä¸€ 0~1ï¼‰
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger

# ==================== åŸºæœ¬åƒæ•¸è¨­å®š ====================
DATA_DIR = 'data'
LABEL_CSV = os.path.join(DATA_DIR, 'labels.csv')
MODEL_DIR = 'A3'
os.makedirs(MODEL_DIR, exist_ok=True)

# === è¶…åƒæ•¸è¨­å®š ===
MAX_SEQ_LEN = 200
FEATURE_DIM = 51
EPOCHS = 500
BATCH_SIZE = 32
DROPOUT_RATE = 0.3
MODEL_NAME = 'A3'

# ==================== è®€å–è³‡æ–™ ====================
df = pd.read_csv(LABEL_CSV)
X_list, y_list = [], []

for _, row in df.iterrows():
    path = os.path.join(DATA_DIR, row['filename'] + '.npy')
    if os.path.exists(path):
        arr = np.load(path)
        if arr.shape[1] != FEATURE_DIM:
            arr = arr[:, :FEATURE_DIM]
        X_list.append(arr)
        y_list.append(row['label'])
    else:
        print(f"âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ: {path}")

X = pad_sequences(X_list, maxlen=MAX_SEQ_LEN, dtype='float32', padding='post', truncating='post')
y = np.array(y_list)

# ==================== åˆ‡åˆ†è³‡æ–™é›† ====================
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.1, random_state=42, stratify=y
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.1111, random_state=42, stratify=y_temp
)
print(f"è³‡æ–™é›†æ¯”ä¾‹ï¼šTrain={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}")

# ==================== æ¨¡å‹æ¶æ§‹ ====================
model = Sequential([
    Masking(mask_value=0.0, input_shape=(MAX_SEQ_LEN, FEATURE_DIM)),

    LSTM(128, return_sequences=True),
    Dropout(DROPOUT_RATE),

    LSTM(64),

    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# ==================== Callback ====================
checkpoint = ModelCheckpoint(
    os.path.join(MODEL_DIR, f'{MODEL_NAME}_best.keras'),
    save_best_only=True, monitor='val_loss', mode='min'
)
early_stop = EarlyStopping(
    monitor='val_loss', patience=30, restore_best_weights=True
)
csv_logger = CSVLogger(os.path.join(MODEL_DIR, f'{MODEL_NAME}_training_log.csv'))

# ==================== è¨“ç·´æ¨¡å‹ ====================
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[checkpoint, csv_logger],
    verbose=1
)

# ==================== å„²å­˜æ¨¡å‹èˆ‡è¨“ç·´æ­·å² ====================
final_model_path = os.path.join(MODEL_DIR, f'{MODEL_NAME}_final.keras')
model.save(final_model_path)
print(f"ğŸ’¾ æœ€çµ‚æ¨¡å‹å·²å„²å­˜è‡³ï¼š{final_model_path}")

# å„²å­˜è¨“ç·´æ­·å²ï¼ˆJSON + CSVï¼‰
history_path_json = os.path.join(MODEL_DIR, f'{MODEL_NAME}_history.json')
with open(history_path_json, 'w') as f:
    json.dump(history.history, f, indent=4)

history_path_csv = os.path.join(MODEL_DIR, f'{MODEL_NAME}_history.csv')
pd.DataFrame(history.history).to_csv(history_path_csv, index=False)
print(f"ğŸ“Š è¨“ç·´æ­·å²å·²å„²å­˜ï¼š{history_path_json}, {history_path_csv}")

# ==================== é©—è­‰èˆ‡æ¸¬è©¦ ====================
val_loss, val_acc = model.evaluate(X_val, y_val)
print(f"\nâœ… é©—è­‰æº–ç¢ºç‡ï¼š{val_acc:.4f} | é©—è­‰æå¤±ï¼š{val_loss:.4f}")

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"ğŸ§ª æ¸¬è©¦æº–ç¢ºç‡ï¼š{test_acc:.4f} | æ¸¬è©¦æå¤±ï¼š{test_loss:.4f}")

# å„²å­˜ train/val/test çµæœæ‘˜è¦
final_results_path = os.path.join(MODEL_DIR, f'{MODEL_NAME}_final_results.csv')
with open(final_results_path, 'w') as f:
    f.write('dataset,loss,accuracy\n')
    f.write(f'train,{history.history["loss"][-1]:.6f},{history.history["accuracy"][-1]:.6f}\n')
    f.write(f'val,{history.history["val_loss"][-1]:.6f},{history.history["val_accuracy"][-1]:.6f}\n')
    f.write(f'test,{test_loss:.6f},{test_acc:.6f}\n')
print(f"ğŸ“„ æœ€çµ‚çµæœå·²å„²å­˜ï¼š{final_results_path}")

# ==================== æ··æ·†çŸ©é™£ï¼ˆTestï¼‰ ====================
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int).flatten()

cm = confusion_matrix(y_test, y_pred, normalize='true')
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Fall'])
disp.plot(cmap=plt.cm.Blues, values_format=".2f")
plt.title(f'Confusion Matrix - {MODEL_NAME}')
plt.savefig(os.path.join(MODEL_DIR, f'{MODEL_NAME}_confusion_matrix.png'))
plt.close()

# ==================== åˆ†é¡å ±å‘Šï¼ˆTestï¼‰ ====================
report = classification_report(y_test, y_pred, target_names=['Normal', 'Fall'], output_dict=True)
report_df = pd.DataFrame(report).transpose()
report_path = os.path.join(MODEL_DIR, f'{MODEL_NAME}_classification_report.csv')
report_df.to_csv(report_path, index=True)
print(f"ğŸ“„ æ¸¬è©¦åˆ†é¡å ±å‘Šå·²å„²å­˜ï¼š{report_path}")

# ==================== ç¹ªè£½è¨“ç·´æ›²ç·šï¼ˆçµ±ä¸€ y è»¸ 0~1ï¼‰ ====================
plt.figure(figsize=(12, 5))

# Loss æ›²ç·š
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title(f'{MODEL_NAME} - Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim(0, 1)
plt.legend()

# Accuracy æ›²ç·š
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title(f'{MODEL_NAME} - Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.legend()

plt.tight_layout()
plot_path = os.path.join(MODEL_DIR, f'{MODEL_NAME}_training_plot.png')
plt.savefig(plot_path)
plt.close()

# ==================== è¼¸å‡ºæ‘˜è¦ ====================
print("\nğŸ“Š æ¸¬è©¦çµæœæ‘˜è¦ï¼š")
print(report_df[['precision', 'recall', 'f1-score', 'support']])
print(f"\nğŸ“ˆ è¨“ç·´æ›²ç·šã€åˆ†é¡å ±å‘Šã€æ··æ·†çŸ©é™£ã€æœ€çµ‚çµæœèˆ‡æ­·å²ç´€éŒ„å·²å„²å­˜è‡³ï¼š{MODEL_DIR}")
